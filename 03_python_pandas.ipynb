{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python für Aktuare Teil 3\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeutscheAktuarvereinigung/Python_fuer_Aktuare/blob/main/03_python_pandas.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/DeutscheAktuarvereinigung/Python_fuer_Aktuare/blob/main/03_python_pandas.ipynb)\n",
    "## Agenda\n",
    "Innerhalb dieses Notebooks behandeln wir:\n",
    "- Pandas Einführung\n",
    "- Series und Dataframes\n",
    "- Datenzugriff und Inspektion\n",
    "- Daten manipulieren und bereinigen\n",
    "- Dateien einlesen\n",
    "\n",
    "# Einführung in Pandas\n",
    "\n",
    "**Pandas** ist eine der beliebtesten Bibliotheken für Datenanalyse und -manipulation in Python. Sie wurde speziell entwickelt, um mit strukturierten Daten effizient und einfach zu arbeiten, ähnlich wie es in Tabellenkalkulationen wie Excel der Fall ist. \n",
    "\n",
    "Pandas bietet zwei Hauptstrukturen zur Handhabung von Daten:\n",
    "- **Series**: Eine eindimensionale Datenstruktur, ähnlich einer Liste oder einem Array.\n",
    "- **DataFrame**: Eine zweidimensionale Datenstruktur, vergleichbar mit einer Tabelle in einer Datenbank oder einem Excel-Spreadsheet.\n",
    "\n",
    "### Warum Pandas?\n",
    "Pandas ist besonders nützlich, wenn es darum geht, große Datenmengen einzulesen, zu verarbeiten und zu analysieren. Typische Aufgaben, die Pandas vereinfacht, sind:\n",
    "- Einlesen von Daten aus verschiedenen Formaten (z.B. CSV, Excel, SQL-Datenbanken).\n",
    "- Effiziente Inspektion und Analyse von Daten.\n",
    "- Datenbereinigung und -manipulation (z.B. fehlende Werte behandeln, Spalten umbenennen).\n",
    "- Umwandlung und Aggregation von Daten für weitere Analysen oder Visualisierungen.\n",
    "\n",
    "Durch seine breite Funktionalität und einfache Handhabung ist Pandas zu einem Standardwerkzeug für Datenanalyse geworden, insbesondere im Bereich Data Science, Finanzanalysen und im Versicherungswesen.\n",
    "\n",
    "Im Folgenden werden wir uns die wichtigsten Funktionen von Pandas ansehen und lernen, wie wir Daten effizient einlesen, analysieren und bereinigen können.\n",
    "\n",
    "### Kritikpunkte an Pandas\n",
    "\n",
    "Obwohl Pandas eine mächtige Bibliothek ist, gibt es auch einige Kritikpunkte, die man im Hinterkopf behalten sollte:\n",
    "\n",
    "1. **Speicher- und Rechenaufwand**: Pandas ist speicherintensiv, da es Daten in den Arbeitsspeicher lädt. Bei sehr großen Datenmengen kann dies zu Leistungsproblemen führen. Für große Datensätze, die nicht in den RAM passen, müssen alternative Tools wie **Dask**, **PySpark** oder **Apache Arrow** in Betracht gezogen werden, die für verteilte Verarbeitung optimiert sind.\n",
    "\n",
    "2. **Komplexität bei großen Datenpipelines**: Für kleinere Projekte und Analysen ist Pandas sehr effizient. Bei größeren Datenpipelines oder komplexen Datenanalysen kann der Code jedoch unübersichtlich und schwer wartbar werden. Insbesondere der Umgang mit sehr vielen verschachtelten Pandas-Funktionen kann den Code schwer verständlich machen.\n",
    "\n",
    "Trotz dieser Einschränkungen bleibt Pandas ein leistungsfähiges Werkzeug für die meisten Datenanalysen, besonders bei mittleren Datensätzen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# um mit Pandas arbeiten zu können muss es natürlich importiert werden\n",
    "import pandas as pd\n",
    "# typischerweise wird auch noch numpy benötigt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "Eine **Pandas Series** ist eine eindimensionale Datenstruktur, die mit einer Liste oder einem Array vergleichbar ist. Sie besteht aus einer Reihe von Werten, die jeweils einem Index zugeordnet sind. Pandas Series können verschiedene Datentypen wie Ganzzahlen, Gleitkommazahlen oder Zeichenketten enthalten.\n",
    "\n",
    "### Eigenschaften einer Series:\n",
    "- **Index**: Jede Series hat einen zugehörigen Index, der standardmäßig von 0 an aufsteigt, aber auch explizit gesetzt werden kann (z.B. Datumsangaben).\n",
    "- **Homogene Daten**: Alle Elemente einer Series haben denselben Datentyp (wie bei Arrays).\n",
    "\n",
    "Series sind nützlich, wenn man mit eindimensionalen Daten arbeiten möchte, wie zum Beispiel eine Liste von Schadensbeträgen in einem Versicherungsportfolio.\n",
    "\n",
    "## Beispiel 1: Schadenverlauf über mehrere Jahre\n",
    "\n",
    "In diesem Beispiel speichern wir den jährlichen Schadenverlauf einer Versicherung als Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schadenverlauf über fünf Jahre\n",
    "jahre = ['2018', '2019', '2020', '2021', '2022']\n",
    "schadenverlauf = pd.Series([10000, 15000, 13000, 12000, 11000], index=jahre)\n",
    "print(schadenverlauf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein anderes Beispiel sind (synthetische) Aktienverläufe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter für die Simulation\n",
    "np.random.seed(42)\n",
    "tage = pd.date_range(start='2023-01-01', periods=365, freq='D')\n",
    "startpreis = 100  # Startpreis der Aktie\n",
    "volatilitaet = 0.02  # Volatilität der Aktie (2%)\n",
    "rendite = 0.001  # Erwartete tägliche Rendite (0,1%)\n",
    "\n",
    "# Generiere tägliche Änderungen basierend auf brownscher Bewegung\n",
    "aenderungen = np.random.normal(loc=rendite, scale=volatilitaet, size=len(tage))\n",
    "\n",
    "# Berechne die Aktienpreise mit kumulativer Summe\n",
    "preise = startpreis * np.exp(np.cumsum(aenderungen))\n",
    "\n",
    "# Erstelle die Pandas Series\n",
    "aktienverlauf = pd.Series(preise, index=tage)\n",
    "\n",
    "# Ausgabe der ersten Tage des Aktienverlaufs\n",
    "print(aktienverlauf.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "Ein **DataFrame** ist das Herzstück von Pandas und stellt eine zweidimensionale, tabellenähnliche Datenstruktur dar, die Spalten und Zeilen enthält. Man kann einen DataFrame als eine Sammlung von Pandas Series betrachten, die eine gemeinsame Struktur haben. Jeder Spalte ist ein eindeutiger Name zugeordnet, und jede Zeile kann durch einen Index referenziert werden.\n",
    "\n",
    "### Eigenschaften eines DataFrames:\n",
    "- **Zeilen und Spalten**: Ein DataFrame besteht aus Zeilen und Spalten, wobei jede Spalte eine eigene Datentypen haben kann (z.B. eine Spalte mit numerischen Werten und eine Spalte mit Zeichenketten).\n",
    "- **Flexibles Indexing**: Man kann sowohl auf Zeilen als auch auf Spalten durch den Index oder Spaltennamen zugreifen.\n",
    "- **Datenquellen**: DataFrames können aus verschiedenen Datenquellen erstellt werden, wie z.B. CSV-Dateien, Excel-Dateien, SQL-Datenbanken oder sogar aus Dictionaries und Listen in Python.\n",
    "\n",
    "## Beispiel 1: Erstellen eines DataFrames für Versicherungsdaten\n",
    "\n",
    "In diesem Beispiel erstellen wir einen DataFrame, der einige grundlegende Informationen zu Versicherungspolicen enthält, wie die Police-ID, den Versicherten, den Prämienbetrag und die Anzahl der Schadensfälle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen eines DataFrames\n",
    "# Definiere die Daten\n",
    "daten = {\n",
    "    'Police_ID': pd.Series([101, 102, 103, 104, 105, 106, 107, 108, 109, 110], dtype='int64'),\n",
    "    'Versicherter': pd.Series(['Max Müller', 'Anna Schmitz', 'Tom Meier', 'Laura Klein', 'Peter Schneider', \n",
    "                               'Julia Weber', 'Stefan Jung', 'Monika Richter', 'Clara Hofmann', 'David Krause'], dtype='string'),\n",
    "    'Alter': pd.Series([18, 47, 49, 14, 15, 31,  1, 54,  3, 16], dtype='int64'),\n",
    "    'Praemienbetrag': pd.Series([500, 600, 550, 620, 480, 700, 520, 610, 580, 540], dtype='float64'),\n",
    "    'Schadensfaelle': pd.Series([2, 1, 0, 3, 2, 1, 1, 0, 4, 2], dtype='int64'),\n",
    "    'Versicherungsbeginn': pd.to_datetime(['2019-01-15', '2020-05-20', '2021-03-10', '2018-11-22', \n",
    "                                           '2019-07-01', '2020-02-17', '2021-09-09', '2022-01-01', \n",
    "                                           '2019-12-25', '2020-06-14'])\n",
    "}\n",
    "\n",
    "# Erstellen des DataFrames\n",
    "versicherungs_df = pd.DataFrame(daten)\n",
    "\n",
    "# Ausgabe des DataFrames\n",
    "versicherungs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achtung, das Dataframe hat keinen expliziten Index. Deswegen vorne die Spalte von 0 bis 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Spaltentypen\n",
    "versicherungs_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nochmal ein Beispiel zu zeitabhängigen (synthetischen) Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter für die Simulation\n",
    "np.random.seed(42)\n",
    "tage = pd.date_range(start='2023-01-01', periods=365, freq='D')\n",
    "\n",
    "# Aktienparameter für verschiedene Firmen\n",
    "firmen = {\n",
    "    'Apple': {'startpreis': 150, 'volatilitaet': 0.02, 'rendite': 0.001},\n",
    "    'Nvidia': {'startpreis': 220, 'volatilitaet': 0.025, 'rendite': 0.0012},\n",
    "    'Google': {'startpreis': 180, 'volatilitaet': 0.018, 'rendite': 0.0008},\n",
    "    'SAP': {'startpreis': 120, 'volatilitaet': 0.015, 'rendite': 0.0009},\n",
    "    'Microsoft': {'startpreis': 250, 'volatilitaet': 0.02, 'rendite': 0.0011},\n",
    "    'Tesla': {'startpreis': 200, 'volatilitaet': 0.03, 'rendite': 0.0015},\n",
    "}\n",
    "\n",
    "# Erstelle einen DataFrame, um alle Aktienverläufe zu speichern\n",
    "aktienverlaeufe = pd.DataFrame(index=tage)\n",
    "\n",
    "# Simulation der Aktienkurse für jede Firma\n",
    "for firma, parameter in firmen.items():\n",
    "    startpreis = parameter['startpreis']\n",
    "    volatilitaet = parameter['volatilitaet']\n",
    "    rendite = parameter['rendite']\n",
    "    \n",
    "    # Generiere tägliche Änderungen basierend auf brownscher Bewegung\n",
    "    aenderungen = np.random.normal(loc=rendite, scale=volatilitaet, size=len(tage))\n",
    "    \n",
    "    # Berechne die Aktienpreise mit kumulativer Summe\n",
    "    preise = startpreis * np.exp(np.cumsum(aenderungen))\n",
    "    \n",
    "    # Füge die Simulation als Serie in den DataFrame ein\n",
    "    aktienverlaeufe[firma] = preise\n",
    "\n",
    "# Ausgabe der ersten 20 Tage der simulierten Aktienverläufe\n",
    "aktienverlaeufe.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt haben wir zwei schöne Beispieldatensätze `versicherungs_df` und `aktienverlaeufe`. Jezt schauen wir mal was wir mit denen anstellen können.\n",
    "\n",
    "# Pandas Standardfunktionen\n",
    "\n",
    "Pandas bietet eine Reihe von hilfreichen Standardfunktionen, um Daten schnell und effizient zu inspizieren. Hier sind einige der wichtigsten:\n",
    "`head()` und `tail()`\n",
    "\n",
    "Mit `head()` und `tail()` kann man die ersten oder letzten Einträge eines DataFrames oder einer Series anzeigen lassen. Dies ist nützlich, um sich einen schnellen Überblick über die Struktur der Daten zu verschaffen. Beispiele (von `head()`) haben wir oben schon gesehen.\n",
    "\n",
    "Interessanter um sich einen ersten Eindruck von einem Datensatz zu machen sind die Funktionen `describe()` und `info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicherungs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aktienverlaeufe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andere wichtige Infos sind bspw. `columns`, `index` oder `shape`. (Achtung keine Funktionen sondern Attribute des DataFrames.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aktienverlaeufe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicherungs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aktienverlaeufe.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenzugriff in Pandas\n",
    "\n",
    "In Pandas gibt es verschiedene Methoden, um auf Daten in einem DataFrame zuzugreifen. Dazu gehören der Zugriff auf Spalten, Zeilen oder bestimmte Elemente mithilfe von `loc` und `iloc`.\n",
    "\n",
    "### Zugriff auf Spalten\n",
    "\n",
    "Auf eine Spalte eines DataFrames kann einfach über den Spaltennamen zugegriffen werden. Es gibt zwei Möglichkeiten:\n",
    "\n",
    "1. Zugriff mit Punktschreibweise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicherungs_df.Versicherter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Mit Spaltennamen in eckigen Klammern (verbreiteter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicherungs_df['Versicherter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zugriff auf Zeilen\n",
    "\n",
    "`loc[]´ – Zugriff nach Labeln (indexbasiert)\n",
    "\n",
    "Mit 'loc[]' kann man auf Zeilen und Spalten basierend auf den Bezeichnungen (Labels) zugreifen. Diese Methode verwendet explizite Indexnamen oder Spaltennamen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aktienverlaeufe.loc['01-01-2023'] #Achtung Datumschreibweise eigentlich falsch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc[]` - integerbasierter Zugriff\n",
    "\n",
    "Mit `iloc[]` greift man auf Zeilen und Spalten basierend auf ihrer Position im DataFrame zu. Dies funktioniert ähnlich wie bei einer Liste in Python, wobei die Indizes 0-basiert sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aktienverlaeufe.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zugriff auf Spalen und Zeilen + Slicing\n",
    "Man kann auch auf Spalten und Zeilen gleichzeitig zugreifen, plus nur Teile der Daten auswählen (*slicing*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# die Aktienverläufe der ersten 5 Tage nur für Apple und Nvidia\n",
    "aktienverlaeufe.loc['2023-01-01':'2023-01-05', ['Apple', 'Nvidia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zugriff auf ein bestimmtes Element:\n",
    "versicherungs_df.iloc[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aktienverlaeufe.loc['2023-12-31', 'Microsoft']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konditionaler Zugriff\n",
    "\n",
    "Zusätzlich zum Zugriff über Spaltennamen oder Indizes kann man auch über Bedingungen auf die Daten zugreifen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle Verträge die im Mai beginnen\n",
    "versicherungs_df[versicherungs_df['Versicherungsbeginn'].dt.month == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur Verträge mit hohen Prämien\n",
    "versicherungs_df[versicherungs_df['Praemienbetrag'] > 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zugriff erfolgt über eine boolesche Maske\n",
    "versicherungs_df['Praemienbetrag'] > 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der konditionale Zugriff ist sehr mächtig, allerdings kann es auch sehr schnell sehr komplex werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aktienverlaeufe[\n",
    "    (aktienverlaeufe.index.month == 5) &  # Filter für den Monat Mai\n",
    "    ((aktienverlaeufe['Nvidia'] > 230) |   # Nvidia > 230 oder\n",
    "    (aktienverlaeufe['Apple'] > 140)) &    # Apple > 155\n",
    "    (aktienverlaeufe['Google'] > 185) &   # Google > 185\n",
    "    (aktienverlaeufe['Tesla'] < 260)      # Tesla < 220\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten anreichern \n",
    "\n",
    "\n",
    "In der Datenanalyse ist es häufig notwendig, bestehende Datensätze zu erweitern, indem man neue Spalten hinzufügt. Dies kann beispielsweise durch Berechnungen, den Import zusätzlicher Daten oder durch die Anwendung von Funktionen geschehen. In Pandas bietet sich eine einfache Möglichkeit, neue Spalten zu erstellen und mit Daten zu füllen.\n",
    "\n",
    "Typische Anwendungsfälle sind:\n",
    "\n",
    "- Berechnung von neuen Werten basierend auf bestehenden Spalten (z.B. Risikobewertungen, Prämienberechnungen)\n",
    "- Hinzufügen von externen Datenquellen (z.B. Inflation, Wechselkurse)\n",
    "- Erzeugen von Kategorien oder Gruppierungen (z.B. Alterseinteilungen, Schadensklassen)\n",
    "\n",
    "Neue Spalten können auf verschiedene Arten erstellt werden, wie z.B. durch einfache Zuweisung, durch Verwendung von Berechnungen oder durch Zuweisung einer konstanten oder berechneten Wertreihe.\n",
    "\n",
    "In den folgenden Beispielen werden wir uns anschauen, wie man neue Spalten zu einem bestehenden DataFrame hinzufügen kann.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertragsdauer in Jahren ergänzen\n",
    "versicherungs_df['Vertragsdauer'] = (pd.to_datetime('today') - versicherungs_df['Versicherungsbeginn']).dt.days / 365\n",
    "versicherungs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der absoluten Performance zum Startwert für die Apple-Aktie\n",
    "aktienverlauf_apple = pd.DataFrame()\n",
    "aktienverlauf_apple['Kurs'] = aktienverlaeufe['Apple']  \n",
    "startwert_apple = aktienverlauf_apple['Kurs'].iloc[0]  # Startwert der Aktie\n",
    "print(f'Simulierter Startwert der Apple-Aktie: {startwert_apple}')\n",
    "aktienverlauf_apple['AbsPerformance'] = aktienverlauf_apple['Kurs'] - startwert_apple\n",
    "\n",
    "# Ausgabe der ersten Zeilen mit der neuen Spalte\n",
    "print(aktienverlauf_apple.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neben einfachen Berechnungen gibt es für viele Anwendungsfälle auch Pandas-Standardfunktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der täglichen relativen Performance\n",
    "aktienverlauf_apple['RelPerformance'] = aktienverlauf_apple['Kurs'].pct_change()\n",
    "aktienverlauf_apple.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten löschen\n",
    "Falls man eine Spalte oder Zeile löschen möchte, geht dies über:\n",
    "\n",
    "- **Zeilen löschen**: Mit `drop(index)` können spezifische Zeilen entfernt werden. Dabei gibt man den Index der Zeilen an, die gelöscht werden sollen.\n",
    "- **Spalten löschen**: Mit `drop(Spaltenname, axis=1)` können spezifische Spalten entfernt werden.\n",
    "\n",
    "Inplace-Option: Wenn man die Änderungen direkt auf dem bestehenden DataFrame durchführen möchte, kann man `inplace=True` verwenden, um eine Kopie des DataFrames zu vermeiden.\n",
    "\n",
    "**Achtung**: `drop()` erlaubt keinen Rückgriff auf die Originaldaten, sobald die Zeilen oder Spalten gelöscht wurden, es sei denn, es wurde zuvor eine Kopie erstellt.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalte löschen\n",
    "aktienverlauf_apple.drop(['RelPerformance'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop liefert einen neuen Dataframe ohne die gelöschten Daten zurück. Ohne `inplace=True` verändert sich der Originaldataframe also nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aktienverlauf_apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. + 4. Zeile löschen\n",
    "aktienverlauf_apple.drop(['2023-01-03', '2023-01-04'], inplace=True) # Achtung der Index ist bei diesem Datenset ein Datum\n",
    "aktienverlauf_apple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe: Arbeiten mit Schadendaten\n",
    "\n",
    "In dieser Aufgabe sollen Sie verschiedene Operationen mit einem Beispiel-Datensatz aus Schadendaten durchführen. Die Daten erstellen wir mit folgendem Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen von Beispiel-Daten\n",
    "daten = {\n",
    "    'Schadens_ID': range(1, 16),\n",
    "    'Versicherungsnummer': [f'VN{str(i).zfill(5)}' for i in np.random.randint(0,10000,15)],  # Zufällige Versicherungsnummern\n",
    "    'Schadenshöhe': np.random.randint(1000, 5000, size=15),  # Zufällige Schadenshöhe zwischen 1000 und 5000\n",
    "    'Schadensdatum': pd.date_range(start='2023-01-01', periods=15, freq='D'),\n",
    "    'Versicherungsbeginn': pd.date_range(start='2021-01-01', periods=15, freq='D'),\n",
    "    'Region': [\n",
    "        'Nord', 'Ost', 'Süd', 'West', 'Nord', \n",
    "        'Ost', 'Süd', 'West', 'Nord', 'Ost', \n",
    "        'Süd', 'West', 'Nord', 'Ost', 'Süd'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben\n",
    "\n",
    "1. **DataFrame erstellen**: Erstellen Sie einen Pandas DataFrame aus den obenstehenden Daten.\n",
    "\n",
    "2. **Daten einsehen**: Verwenden Sie die Methoden `head()` und `describe()`, um einen Überblick über den Datensatz zu erhalten. Was fällt Ihnen auf?\n",
    "\n",
    "3. **Filtern der Daten**: Filtern Sie die Schadensfälle, die eine Schadenshöhe von mehr als 2000 haben. Welche Versicherungsnehmer sind betroffen?\n",
    "\n",
    "4. **Vertragsdauer ermitteln**: Fügen Sie eine neue Spalte `Vertragsdauer` hinzu, die die Dauer des Vertrags in Tagen bis zum Schadensdatum angibt.\n",
    "\n",
    "5. **Berechnung der durchschnittlichen Schadenshöhe**: Berechnen Sie die durchschnittliche Schadenshöhe der Schadensfälle.\n",
    "\n",
    "6. **Gruppieren der Schadenhöhe**: Gruppieren Sie die Schadenhöhen nach der Region\n",
    "\n",
    "\n",
    "\n",
    "## Hinweis\n",
    "\n",
    "Sie können die Funktionen von Pandas verwenden, um die oben genannten Aufgaben zu lösen. Achtung das Vorgehen für  6. haben wir noch nicht besprochen. Schauen Sie sich dazu einmal die Dokumentation zu `mean()` und einmal zu `groupby()` an. ([Dokumenation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby))\n",
    "\n",
    "Die Anzahl der verschiedenen Ausprägungen in der Spalte *Region* erhalten Sie mit der Funktion `value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ergänzen Sie nach Bedarf Code-Zeilen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten gruppieren und Aggregierungsfunktionen in Pandas\n",
    "\n",
    "In der Datenanalyse ist es häufig notwendig, Daten zu gruppieren, um aggregierte Statistiken zu berechnen. Pandas bietet leistungsstarke Funktionen, um Daten zu gruppieren und verschiedene Aggregierungsoperationen durchzuführen.\n",
    "\n",
    "## Grundlegende Konzepte\n",
    "\n",
    "- **Gruppierung**: Die Gruppierung von Daten erfolgt mithilfe der `groupby()`-Methode. Diese Methode teilt die Daten in Gruppen basierend auf den Werten einer oder mehrerer Spalten auf.\n",
    "- **Aggregierung**: Nach der Gruppierung können verschiedene Aggregierungsfunktionen angewendet werden, um statistische Kennzahlen zu berechnen. Zu den häufig verwendeten Aggregierungsfunktionen gehören:\n",
    "  - `mean()`: Berechnet den Durchschnitt.\n",
    "  - `sum()`: Berechnet die Summe.\n",
    "  - `count()`: Zählt die Anzahl der Elemente.\n",
    "  - `max()`: Bestimmt den maximalen Wert.\n",
    "  - `min()`: Bestimmt den minimalen Wert.\n",
    "\n",
    "## Beispiel: Schadensdaten aggregieren\n",
    "\n",
    "Angenommen, wir haben einen DataFrame `schaden_daten` mit Schadensinformationen, der eine Spalte für die Region und eine für die Schadenshöhe enthält. Wir können den durchschnittlichen Schaden pro Region wie folgt berechnen:\n",
    "\n",
    "```python\n",
    "durchschnitt_schaden = schaden_daten.groupby('Region')['Schadenshöhe'].mean()\n",
    "print(durchschnitt_schaden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivotisieren mit Pandas\n",
    "\n",
    "Das Pivotisieren in Pandas ermöglicht es, die Daten in eine übersichtliche Tabelle zu transformieren, ähnlich wie bei Pivot-Tabellen in Excel. Mit der `pivot()`-Funktion kann man Daten anhand von Schlüsselspalten (wie Kategorien, Regionen oder Zeitangaben) umstrukturieren. Dabei wird eine Spalte für die Werte verwendet, die man aggregieren oder darstellen möchte, während andere Spalten als Index oder Spaltenüberschriften genutzt werden.\n",
    "\n",
    "## Beispiel für das Pivotisieren:\n",
    "\n",
    "Angenommen, wir möchten eine Übersicht erstellen, wie hoch die durchschnittliche Schadenshöhe in den verschiedenen Regionen war."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot-Tabelle erstellen, die den Mittelwert der Schadenshöhen nach Region zeigt\n",
    "schaden_pivot = schaden_daten.pivot_table(values='Schadenshöhe', index='Region', aggfunc='mean')\n",
    "schaden_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einlesen und Schreiben von Daten in Pandas-DataFrames\n",
    "\n",
    "Pandas bietet leistungsstarke Funktionen zum Einlesen von Daten aus verschiedenen Dateiformaten und zum Schreiben von DataFrames in Dateien. Die gängigsten Formate sind CSV (Comma-Separated Values) und Excel, es gehen aber auch JSON, HTML, Latex, Parquet, SAS ...\n",
    "\n",
    "## Einlesen von Daten\n",
    "Um Daten aus einer CSV-Datei in ein Pandas-DataFrame einzulesen, verwenden Sie die `read_csv()`-Funktion. Hier ist ein Beispiel:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Einlesen einer CSV-Datei\n",
    "df_csv = pd.read_csv('dateipfad/zur_datei.csv')\n",
    "\n",
    "# Ausgabe der ersten fünf Zeilen des DataFrames\n",
    "print(df_csv.head())\n",
    "```\n",
    "\n",
    "Ebenso einfach funktioniert das Einlesen einer Excel-Datei\n",
    "```python\n",
    "# Einlesen einer Excel-Datei\n",
    "df_excel = pd.read_excel('dateipfad/zur_datei.xlsx', sheet_name='Tabelle1')\n",
    "\n",
    "# Ausgabe der ersten fünf Zeilen des DataFrames\n",
    "print(df_excel.head())\n",
    "```\n",
    "\n",
    "## Schreiben von Daten\n",
    "Um ein DataFrame in eine CSV-Datei zu schreiben, verwenden Sie die `to_csv()`-Funktion. Hier ein \n",
    "```python\n",
    "# Schreiben des DataFrames in eine CSV-Datei\n",
    "df_csv.to_csv('dateipfad/zur_neuen_datei.csv', index=False)\n",
    "```\n",
    "\n",
    "oder \n",
    "```python\n",
    "# Schreiben des DataFrames in eine Excel-Datei\n",
    "df_excel.to_excel('dateipfad/zur_neuen_datei.xlsx', sheet_name='Tabelle1', index=False)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dateien von nicht lokalen Quellen einlesen\n",
    "\n",
    "Man kann mit `pandas`aus sehr einfach Datenquellen einlesen, die nicht lokal sondern \"irgendwo\" im Internet, bzw. auf einem Server liegen. Man dazu nur die URL zum Speicherort der Datei angeben. \n",
    "\n",
    "Beispielsweise können wir so die Dateien im github-Repository einlesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/DeutscheAktuarvereinigung/Python_fuer_Aktuare/refs/heads/main/data/weather_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umgang mit fehlenden Daten\n",
    "\n",
    "In realen Datensätzen sind fehlende Daten ein häufiges Problem. Pandas bietet eine Vielzahl von Methoden, um fehlende Werte zu identifizieren, zu bearbeiten oder zu bereinigen.\n",
    "\n",
    "### Fehlende Daten erkennen\n",
    "Mit der Funktion `isnull()` oder `isna()` können Sie erkennen, welche Einträge in einem DataFrame fehlen. `isnull()` gibt `True` zurück, wenn der Wert fehlt (NaN), und `False`, wenn ein gültiger Wert vorhanden ist.\n",
    "\n",
    "Schauen wir uns das an unserem Versicherungsdatensatz von oben einmal an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bisher hat der Datensatz keine fehlenden Werte also erzeugen wir welche\n",
    "nan_df = versicherungs_df.copy()\n",
    "\n",
    "\n",
    "# Zufällig NaN-Werte einfügen (ca. 25% der Daten)\n",
    "for col in ['Alter', 'Versicherungsbeginn', 'Vertragsdauer']:\n",
    "    nan_df.loc[nan_df.sample(frac=0.25).index, col] = np.nan\n",
    "\n",
    "nan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fehlende Daten entfernen\n",
    "\n",
    "Mit `dropna()` können Sie Zeilen oder Spalten mit fehlenden Werten entfernen. Sie können steuern, ob alle fehlenden Werte (how='all') oder nur einzelne fehlende Werte (how='any') berücksichtigt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = nan_df.dropna()\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fehlende Daten auffüllen\n",
    "\n",
    "Statt fehlende Werte zu entfernen, können wir diese auch durch sinnvolle Werte ersetzen. Dies kann z.B. der Mittelwert, Median oder ein festgelegter Wert sein. Verwenden Sie hierfür die Funktion `fillna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df['Alter'].fillna(nan_df['Alter'].mean(), inplace=True)\n",
    "nan_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe\n",
    "Jetzt sind Sie dran. Im Ordner *data* finden Sie zwei Datensets:\n",
    "- car_insurance_claims.csv (Autoversicherungsdaten)\n",
    "- titanic_train.csv (Daten der Titanic Passagiere)\n",
    "\n",
    "Quelle:\n",
    "\n",
    "Die Autoversicherungsdaten stammen von [Databrick](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/4954928053318020/1058911316420443/167703932442645/latest.html). Leider ist dort keine weitere Quelle angegeben.\n",
    "\n",
    "Die Titanic-Daten sind der [Titanic-Machine-Learning-Challenge](https://www.kaggle.com/c/titanic/data) von kaggle entnommen und enthalten die Daten von 892 Passagieren der Titanic. Das Datenset wird in der Challenge zum Training von Machine-Learning-Algorithmen verwendet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben zum Schadensfall-Datensatz\n",
    "\n",
    "1. Überblick verschaffen\n",
    "- **Aufgabe**: Lesen Sie den Datensatz ein und verschaffen Sie sich einen Überblick.\n",
    "  - Verwenden Sie `head()`, um sich die ersten 5 Zeilen des Datensatzes anzusehen.\n",
    "  - Nutzen Sie `info()`, um Informationen über die Datentypen und die Anzahl der Einträge zu erhalten.\n",
    "  - Zeigen Sie eine Zusammenfassung der numerischen Spalten mit `describe()`.\n",
    "\n",
    "2. Spaltenzugriff und einfache Berechnungen\n",
    "- **Aufgabe**: Arbeiten Sie mit einzelnen Spalten.\n",
    "  - Zeigen Sie die durchschnittliche Höhe der `total_claim_amount` (Gesamtforderung).\n",
    "  - Finden Sie den maximalen und minimalen Wert für die Spalte `policy_annual_premium` (Jahresprämie).\n",
    "  - Erstellen Sie eine neue Spalte `claim_ratio`, die den Anteil des `total_claim_amount` an der `policy_annual_premium` berechnet.\n",
    "\n",
    "3. Filtern von Daten\n",
    "- **Aufgabe**: Filtern Sie den Datensatz nach bestimmten Bedingungen.\n",
    "  - Finden Sie alle Fälle, bei denen das `incident_type` (Schadenart) als \"Single Vehicle Collision\" gemeldet wurde.\n",
    "  - Zeigen Sie alle Vorfälle an, die im Bundesstaat \"NY\" (`incident_state`) stattgefunden haben und bei denen die Schadenshöhe (`total_claim_amount`) über 10.000 liegt.\n",
    "  - Finden Sie alle Vorfälle, bei denen mehr als 2 Zeugen (`witnesses`) angegeben wurden.\n",
    "\n",
    "4. Gruppieren und Aggregieren\n",
    "- **Aufgabe**: Gruppieren Sie Daten und berechnen Sie Durchschnittswerte.\n",
    "  - Gruppieren Sie die Daten nach dem `incident_state` und zeigen Sie die durchschnittliche `total_claim_amount` für jeden Bundesstaat.\n",
    "  - Gruppieren Sie die Daten nach `insured_occupation` (Beruf des Versicherten) und zeigen Sie die mittlere Höhe des `injury_claim` (Körperschaden) an.\n",
    "  - Finden Sie den durchschnittlichen `property_claim` (Sachschaden) nach `auto_make` (Autohersteller).\n",
    "\n",
    "5. Umgang mit fehlenden Daten\n",
    "- **Aufgabe**: Behandeln Sie fehlende Daten.\n",
    "  - Finden Sie heraus, in welchen Spalten fehlende Werte (`NaN`) vorhanden sind.\n",
    "  - Zählen Sie die fehlenden Werte in der Spalte `authorities_contacted`.\n",
    "  - Füllen Sie die fehlenden Werte in der Spalte `authorities_contacted` mit dem Wert \"Not Contacted\".\n",
    "\n",
    "6. Zeitbasierte Analysen\n",
    "- **Aufgabe**: Arbeiten Sie mit Zeitdaten.\n",
    "  - Konvertieren Sie die Spalte `incident_date` in das Datumsformat (`datetime`).\n",
    "  - Finden Sie heraus, in welchem Monat die meisten Vorfälle stattgefunden haben.\n",
    "  - Zeigen Sie alle Vorfälle an, die zwischen dem 15.02.2015 und dem 28.02.2015 gemeldet wurden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben: Analysen zum Titanic-Datensatz\n",
    "\n",
    "1. **Wer war der jüngste Passagier?**  \n",
    "   Ermitteln Sie das Alter des jüngsten Passagiers an Bord der Titanic. Nutzen Sie dafür die Spalte `Age`. Was können Sie über diesen Passagier noch herausfinden?\n",
    "\n",
    "2. **Überlebensrate nach Geschlecht**  \n",
    "   Untersuchen Sie, ob das Überleben auf der Titanic etwas mit dem Geschlecht der Passagiere zu tun hatte. Berechnen Sie die Überlebensrate für Männer und Frauen getrennt. Nutzen Sie hierfür die Spalten `Survived` und `Sex`.\n",
    "\n",
    "3. **Überlebenschancen in den verschiedenen Klassen**  \n",
    "   Hat die Klasse, in der ein Passagier gereist ist, einen Einfluss auf die Überlebenschancen? Berechnen Sie die Überlebensrate für jede der drei Klassen (`Pclass`) und interpretieren Sie das Ergebnis.\n",
    "\n",
    "4. **Durchschnittliche Ticketpreise pro Klasse**  \n",
    "   Finden Sie heraus, wie viel Passagiere durchschnittlich in den einzelnen Klassen für ihr Ticket bezahlt haben. Verwenden Sie die Spalten `Pclass` und `Fare`, um die durchschnittlichen Ticketpreise zu berechnen.\n",
    "\n",
    "5. **Größte Familien an Bord**  \n",
    "   Finden Sie heraus, wie viele Geschwister und Elternteile (Spalten `SibSp` und `Parch`) die Passagiere an Bord hatten. Wer reiste mit der größten Familie?\n",
    "\n",
    "6. **Wo sind die meisten Passagiere zugestiegen?**  \n",
    "   Untersuchen Sie, an welchem Hafen (`Embarked`) die meisten Passagiere zugestiegen sind. \n",
    "\n",
    "7. **Verteilung der Altersgruppen**  \n",
    "   Teilen Sie die Passagiere in verschiedene Altersgruppen ein (z.B. Kinder, Jugendliche, Erwachsene, Senioren) und untersuchen Sie, wie sich diese Gruppen auf die Überlebensrate auswirken.\n",
    "\n",
    "8. **Wertvollstes Ticket an Bord**  \n",
    "   Finden Sie heraus, welches das teuerste Ticket (`Fare`) auf der Titanic war und wer dieses gekauft hat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
